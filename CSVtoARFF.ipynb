{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "#import necessary libraries\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning) #suppress NumPy's future warning about scalars\n",
    "print('x' in np.arange(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#determine if given s can be parsed as a float\n",
    "def isNumber(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#return only rows whose index is divisible by the given interval\n",
    "def createSubset(data,interval):\n",
    "    ind = [i for i in range(len(data)) if i%interval==0]\n",
    "    #ind = [i for i in range(100) if i%10==0]\n",
    "    return data.iloc[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clean data\n",
    "def clean(data, errorCodes):\n",
    "    newData = pd.DataFrame(columns=data.columns.values.tolist())\n",
    "    for column in data:\n",
    "        n = []\n",
    "        for i, item in enumerate(data[column]):\n",
    "            if item in errorCodes:\n",
    "                n.append(float('nan'))\n",
    "            else:\n",
    "                n.append(item)\n",
    "        newData[column]=n\n",
    "    return newData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import data from file\n",
    "def parsefile(filename):\n",
    "    return pd.read_csv(filename, sep=',', header=0)\n",
    "\n",
    "#translate an array into a comma delimited string\n",
    "def tocsvlist(x):\n",
    "    output = \"\"\n",
    "    for item in x:\n",
    "        output = output + str(item) + \",\"\n",
    "    return output[:-1] #skip the final \",\"\n",
    "\n",
    "#take a csv file as input and output an arff\n",
    "def dataTranformation(location, name, file, interval, errorCodes):\n",
    "    #clean the data, remove empty values, \n",
    "    data = createSubset(clean(parsefile(file), errorCodes), interval)\n",
    "    #remove NAN values from dataset, replace with arff code for missing value \"?\"\n",
    "    data = data.fillna('?')\n",
    "    colHeaders = data.columns.values.tolist()\n",
    "    #if any value contains spaces, put the value in double quotes\n",
    "    for m in range(len(colHeaders)):\n",
    "        if colHeaders[m].find(\" \") != -1:\n",
    "            colHeaders[m] = '\"' + colHeaders[m] + '\"'\n",
    "    #generate lists of each unique value for each column (possible attribute values, exclude ? from lists)\n",
    "    #except numeric ones\n",
    "    a = []\n",
    "    for column in data:\n",
    "        a.append(data[column].unique())\n",
    "    for i in range(len(a)):\n",
    "        a[i] = np.delete(a[i], np.where(a[i] == '?'))\n",
    "        for j in range(len(a[i])):\n",
    "            a[i][j] = str(a[i][j]).strip()\n",
    "            if str(a[i][j]).find(\" \") != -1:\n",
    "                a[i][j] = '\"' + a[i][j] + '\"'\n",
    "        a[i] = np.unique(a[i])\n",
    "    #build a header for the arff\n",
    "    header = \"@relation \" + name + \"\\n\\n\"\n",
    "    i=0;\n",
    "    #print a list of all possible values for each attribute (column). print \"real\" if the column is numeric\n",
    "    for item in colHeaders:\n",
    "        header = header + \"@attribute \" + item\n",
    "        if len(a[i])>0 and isNumber(a[i][0]):\n",
    "            header = header + \" real\\n\"\n",
    "        else:\n",
    "            header = header + \" {\" + tocsvlist(a[i]) + \"}\\n\"\n",
    "        i=i+1\n",
    "    #print the body of the data\n",
    "    #print each row as an arff instance\n",
    "    body = \"\\n\\n@data\\n\"\n",
    "    for row in data.itertuples():\n",
    "        line = \"\"\n",
    "        for i in range(len(colHeaders)):\n",
    "            t = str(row[i+1]).strip()\n",
    "            if t.find(\" \") != -1:\n",
    "                t = '\"' + t + '\"'\n",
    "            line = line + t + \",\"\n",
    "        line = line[:-1]\n",
    "        body = body + line + \"\\n\"\n",
    "    #write string to a new file\n",
    "    newfile = header + body\n",
    "    f = open(location + \".arff\", \"w+\")\n",
    "    f.write(newfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data transformation function takes arguments:\n",
    "    #NameOfNewFile (without file extension)\n",
    "    #NameOfNewRelation for new ARFF\n",
    "    #Path\\To\\NameOfExistingCSVFile.csv\n",
    "    #Interval as integer, if you want your arff file to contain a subset of data from the CSV file\n",
    "    #errorCodes - array of anything you would like to remove from the dataset\n",
    "dataTranformation('NameOfNewFile','NameOfNewRelation','Path\\To\\NameOfExistingCSVFile.csv', 1, ['NAN'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
